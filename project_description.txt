# Allin - AI Assistant for New Software Engineers

**Your Role:** You are an expert Python developer specializing in AI/ML applications, real-time systems, data processing pipelines, and API development using FastAPI. You build robust, modular, and scalable code suitable for cloud deployment.

**Project Context:** You are tasked with building "Allin," an AI-powered assistant designed by Team 8. Allin aims to help new software engineers by providing real-time guidance (via voice and text). It will leverage a Retrieval-Augmented Generation (RAG) system using Supabase for data storage and vector search, and maintain conversational context. The final product will be a web application deployed via FastAPI.

**Core Objective:** Develop the Allin application, focusing on a modular architecture. Key features include real-time interaction, robust conversational memory (using both Mem0ai for summarized context and Supabase for detailed chat logs), and future integration of voice capabilities and a RAG system.

**Developer Guidance:**
* **Use Context7:** Leverage the Context7 MCP server during development to fetch the latest documentation for libraries and APIs, especially for Google AI, Mem0ai, and Supabase components.
* **Use Sequential Thinking:** Employ the Sequential Thinking MCP server to break down complex implementation tasks, plan architectural decisions, and refine logic step-by-step.
* **AI Assistant Environment Note:** The AI assistant collaborating on this project MUST execute any necessary terminal commands using **PowerShell** syntax, as the development environment is Windows.

**Key Technical Stack & Plans:**

* **Framework:** FastAPI for the web application backend.
* **Real-time Communication:** WebSockets within FastAPI for real-time bidirectional communication.
* **AI Models & Configuration:**
    * **Core Interaction:** Google GenAI models (e.g., `gemini-2.0-flash-live-001` for live, `gemini-2.0-flash` for other tasks).
    * **System Prompt:** A comprehensive system prompt defining Allin's identity, behavior, and RAG usage.
* **Conversational Memory & History:**
    * **Mem0ai:** Used for generating and retrieving summarized, long-term memories to provide broad context to the AI during live interactions. Context is shared per user across different chat sessions.
    * **Supabase (PostgreSQL):** Will be used to store detailed, raw conversational turns (`user_id`, `chat_id`, `role`, `content`, `timestamp`) in a `chat_turns` table. This will provide a viewable chat history similar to standard messaging applications.
    * **Multi-Chat:** Implemented `chat_id` to distinguish between different chat sessions for a user.
* **Future - RAG System:**
    * **Data Storage:** Supabase Storage for raw documents (PDFs, text, images). Supabase PostgreSQL for structured data and metadata.
    * **Vector Store:** Supabase PostgreSQL with the `pgvector` extension for storing embeddings and performing similarity searches.
    * **Process:** Documents will be chunked, embedded, and stored. User queries will be used to retrieve relevant chunks to augment LLM prompts.
* **Future - Voice Chat:**
    * **Audio Storage:** Supabase Storage for raw audio files.
    * **Metadata & Transcriptions:** Supabase PostgreSQL to store transcriptions and metadata related to voice turns.
* **Database & Backend:**
    * **Supabase:** Primary backend solution providing PostgreSQL, Object Storage, and potentially Authentication and Edge Functions. Chosen for its generous free tier and open-source nature.
* **Identity:** Must identify as "Allin" from "Team 8" consistently.
* **Environment:** Conda environment `allin_env`.
* **Configuration:** Environment variables via `python-dotenv`.

**Current Status & Implemented Features:**
*   Basic FastAPI application structure with WebSocket endpoint (`/ws/{user_id}/{chat_id}`).
*   `InteractionManager` for managing message flow.
*   `MemoryManager` integrating `mem0ai` for adding and retrieving summarized memories based on user ID.
*   API endpoints:
    *   `/api/v1/chat/history/{user_id}/{chat_id}` (currently attempts to retrieve from Mem0ai, will be updated to use Supabase).
    *   `/api/v1/chat/chats/{user_id}` (lists unique chat_ids from Mem0ai metadata).
*   Initial implementation of `chat_id` for multi-chat distinction.

**Immediate Next Steps:**
1.  **Supabase Integration:**
    *   Create the `chat_turns` table in Supabase PostgreSQL.
    *   Integrate the `supabase-py` Python client into the FastAPI application.
    *   Modify the application to save all raw chat turns (user messages and AI responses) to the `chat_turns` table.
    *   Update the `/api/v1/chat/history/{user_id}/{chat_id}` endpoint to fetch and display conversational history from this table.
2.  **Refine Chat UI/UX:** (Conceptual) Plan how users will interact with multiple chats and view history.

**Future Phases (High-Level):**
*   Full implementation of Voice Chat capabilities.
*   Development and integration of the RAG system.
*   Implementation of session resumption for WebSocket connections.
*   Completion of all planned API endpoints.
*   Deployment of the application.
